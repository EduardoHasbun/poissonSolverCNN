globals:                                    # Domain sizes and others, used to compute global attributes
    nnx: 101                                # Number of points in x direction
    nny: 101                                # Number of points in y direction
    xmin: 0.0
    xmax: 1.0e-2
    ymin: 0.0
    ymax: 1.0e-2

arch:
    scales:
        scale_0: [[1, 30, 20], [40, 30, 1]]
        scale_1: [[20, 20, 20], [40, 20, 20]]
        scale_2: [[20, 16, 16, 20], [40, 16, 16, 20]]
        scale_3: [[20, 20, 20], [40, 20, 20]]
        scale_4: [[20, 60, 20]]
    kernel_sizes: 3
        

data_loader:
    data_dir: 'C:/Codigos/poissonSolverCNN_Gpu/testing/dataset/generated/random_data.npy'   # Dataset path
    batch_size: 64


loss:
    args:
        bound_weight: 1.0                   # Weighting of the loss on the boundaries (float)
        lapl_weight: 2.0e+6                 # Weighting of the loss on the Laplacian (float)
        optimizer_lr: 2.e-4    

trainer:
    epochs: 7                              # Number of epochs
    save_dir: 'debug/'                      # Output directory
    save_period: 10                         # Output period
    plot_period: 10                         # Period to send plots to TensorBoard












# general:
#     name_case: 'unet_model'  
#     data_dir: 'dataset/generated/random_data.npy' 


# arch:
#     model: "UNet"
#     arch_dir: 'Archs/Unet_ks3_rf200.yml'
#     type: 'UNet5'


# globals:                                    # Domain sizes and others, used to compute global attributes
#     nnx: 101                                # Number of points in x direction
#     nny: 101                                # Number of points in y direction
#     xmin: 0.0
#     ymin: 0.0
#     xmax: 1.0e-2
#     ymax: 1.0e-2



# data_loader:
#     batch_size: 64


# loss:
#     args:
#         bound_weight: 1.0                  # Weighting of the loss on the boundaries (float)
#         lapl_weight: 2.0e+6                   # Weighting of the loss on the Laplacian (float)
#         optimizer_lr: 2.e-4                   # Learning rate of the optimizer (float)   

# trainer:
#     epochs: 20                           # Number of epochs